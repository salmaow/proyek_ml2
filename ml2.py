# -*- coding: utf-8 -*-
"""ml2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IJu244COX70hx8n2SyGuooPR6BUDYjwu

# ML Terapan - Salma Oktarina

# Sistem Rekomendasi Buku
Sumber: https://www.kaggle.com/datasets/valakhorasani/best-books-of-the-decade-2020s

## Import Libraries
"""

# Install library yang diperlukan
!pip install pandas numpy==1.24.4 scikit-learn scikit-surprise matplotlib seaborn pandas

# Import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from surprise import Reader, Dataset, SVD, KNNBasic
from surprise.model_selection import train_test_split as surprise_train_test_split
from surprise import accuracy
import re

"""## Loading Dataset"""

# Mout google drive
from google.colab import drive
drive.mount('/content/drive')
path = '/content/drive/MyDrive/proyek_ml2/'

# Data load
books_df = pd.read_csv(path + 'best_books_2020s.csv')
users_df = pd.read_csv(path + 'user_reviews.csv')

print("Shape of books_df:", books_df.shape)
print("Shape of users_df:", users_df.shape)

"""- Dataset buku terdiri dari 6 fitur dan 2.329 entri data.
- Dataset user terdiri dari 3 fitur dan 600.000 entri data.

## Data Understanding
"""

# Dataset buku
print("Info books_df:")
books_df.info()
print("\nMissing values di books_df:")
print(books_df.isnull().sum())
print("\nDuplikasi di books_df:")
print(books_df.duplicated().sum())
print("\nbooks_df 5 baris pertama:")
print(books_df.head())

"""- Index: kode unik setiap buku.
- Book Name: judul dari buku.
- Author: penulis buku.
- Rating: rata-rata ulasan yang diberikan user (1-5).
- Number of Votes: total vote untuk buku.
- Score: jumlah score dari ulasan buku dan total vote buku.

- Terdiri dari 2 kolom bertipe numerik dan 4 kolom bertipe string.
- Tidak ada missing values (null) artinya data siap dianalisis lebih lanjut.
- Tidak adanya duplikasi data artinya data sudah sesuai.
"""

# Dataset user
print("Info users_df:")
users_df.info()
print("\nMissing values di users_df:")
print(users_df.isnull().sum())
print("\nDuplikasi di users_df:")
print(users_df.duplicated().sum())
print("\nusers_df 5 baris pertama:")
print(users_df.head())

# Melihat jumlah duplikasi per kolom
for col in users_df.columns:
    dup_vals = users_df[col].value_counts()
    dup_vals = dup_vals[dup_vals > 1]
    if not dup_vals.empty:
        print(f"Kolom '{col}' memiliki nilai duplikat berikut:\n{dup_vals}\n")

"""- userId: kode unik setiap user.
- bookIndex: kode unik setiap buku dari dataset buku.
- score: score atau ulasan yang diberikan user untuk setiap buku (1-5).

- Terdiri dari 3 kolom bertipe numerik.
- Tidak adanya missing values (null) dan data siap dianalisis lebih lanjut.
- Terdapat duplikasi data sebanyak 175 entri.
"""

#Visualisasi Distribusi Rating Buku
plt.figure(figsize=(10, 6))
sns.countplot(x='score', data=users_df, palette='viridis')
plt.title('Distribution of Book Ratings')
plt.xlabel('Book Rating')
plt.ylabel('Count')
plt.show()

print("Rating terbanyak: ")
print(users_df['score'].value_counts())

"""- Rating 1 merupakan rating terbanyak yang diberikan user pada setiap buku yaitu 120.498
- Rating 5 merupakan rating terkecil yang diberikan user kepada buku yaitu 119.488

## Data Preparation
"""

books_df = books_df.rename(columns={'Index': 'bookIndex'})
books_df.info()

"""- Perubahan nama kolom pakai books_df agar sama seperti users_df"""

# Drop duplicates pada users_df
users_df.drop_duplicates(inplace=True)
print("Shape of users_df setelah drop duplicates:", users_df.shape)

"""- Karena terdapat duplikasi sebanyak 175 entri data langsung srop dan jumlah datanya menjadi 599.825 tetap dengan 3 kolom"""

# Persiapan dataset users_df
# Untuk Content-Based, kita hanya perlu books_df yang sudah bersih.
# Untuk Collaborative Filtering, kita perlu users_df.

# Filter rating eksplisit untuk Collaborative Filtering
ratings_explicit_df = users_df[users_df['score'] != 0]
print(f"\nOriginal ratings: {len(users_df)}, Explicit ratings: {len(ratings_explicit_df)}")

# Gabungkan dengan informasi buku untuk kemudahan
full_data_explicit = ratings_explicit_df.merge(books_df[['bookIndex', 'Book Name']], on='bookIndex')

print("\nFirst 5 rows of merged explicit ratings data:")
print(full_data_explicit.head(10))

full_data_explicit.duplicated().sum()

"""- Rating yang diberikan user sebanyak 599.825 dan kabar baiknya secara eksplisit jadi memudahkan dalam menganalisis data dalam sistem rekomendasi ini.
- Tampilan dari beberapa baris pertama ini disatukan menjadi userId, bookIndex, dan Book Name agar mudah dipanggil.
- Setelah dicek penggabungan di atas terlihat tidak adanya duplikasi data ya.
"""

# Filtering untuk Collaborative Filtering (mengurangi sparsity)
# Pertimbangkan pengguna yang memberi setidaknya N rating dan buku yang menerima setidaknya M rating
min_ratings_user = 3 # Contoh threshold
user_counts = full_data_explicit['userId'].value_counts()
active_users = user_counts[user_counts >= min_ratings_user].index
filtered_ratings_cf = full_data_explicit[full_data_explicit['userId'].isin(active_users)]

min_ratings_book = 3 # pakai threshold
book_counts = filtered_ratings_cf['bookIndex'].value_counts()
popular_books = book_counts[book_counts >= min_ratings_book].index
filtered_ratings_cf = filtered_ratings_cf[filtered_ratings_cf['bookIndex'].isin(popular_books)]
print(f"\nShape of filtered_ratings_cf for Collaborative Filtering: {filtered_ratings_cf.shape}")

if filtered_ratings_cf.empty:
    print("WARNING: filtered_ratings_cf kosong. Thresholds untuk filtering sebaiknya lebih besar.")
else:
    print("Filtered ratings for CF siap.")

filtered_ratings_cf.head()

"""- Proses pemfilteran data rating telah berhasil diselesaikan untuk keperluan Collaborative Filtering
- Menghasilkan dataset siap pakai yang diberi nama filtered_ratings_cf (564113, 4), yang berarti terdiri dari 564.113 baris data (kemungkinan merepresentasikan interaksi pengguna-buku berupa rating) dengan 4 kolom atribut (seperti userId, bookIndex, score, Book Name.), yang kini siap digunakan untuk melatih atau mengaplikasikan model rekomendasi berbasis kolaborasi

## Modeling Content-Based Filtering
"""

# Content-Based Filtering
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
books_cb_sample = books_df.copy()

# Gunakan 'books_cb_sample' di langkah selanjutnya
books_cb_sample.fillna('', inplace=True)
books_cb_sample['content'] = books_cb_sample['Book Name'] + ' ' + books_cb_sample['Author']

# Inisialisasi TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2))

# Membuat matriks TF-IDF dari sample
print("Menerapkan TF-IDF pada sample")
tfidf_matrix_sample = tfidf.fit_transform(books_cb_sample['content'])
print("Shape of TF-IDF matrix (sample):", tfidf_matrix_sample.shape)

# Menghitung kemiripan pada sample
print("Menghitung kemiripan pada sample dengan cosine_similarity")
# cosine_sim_cb_sample = linear_kernel(tfidf_matrix_sample, tfidf_matrix_sample)
cosine_sim_cb_sample = cosine_similarity(tfidf_matrix_sample, tfidf_matrix_sample)
print("Shape of Similarity matrix (sample):", cosine_sim_cb_sample.shape)

# Membuat mapping dari bookIndex ke Indeks untuk sampleL
books_cb_sample.reset_index(drop=True, inplace=True) # Reset index sample
indices_cb_sample = pd.Series(books_cb_sample.index, index=books_cb_sample['bookIndex']).drop_duplicates()

# Fungsi untuk mendapatkan rekomendasi (disesuaikan untuk sampel)
def get_content_based_recommendations_sample(bookindex, N=10):
    if bookindex not in indices_cb_sample:
        return f"bookIndex {bookindex} tidak ditemukan pada sample list bookIndex unik."

    try:
      idx = indices_cb_sample[bookindex]
      if isinstance(idx, pd.Series): idx = idx.iloc[0]
    except KeyError:
        return f"bookIndex {bookindex} tidak ditemukan pada sample mapping."
    except Exception as e:
        return f"Error menemukan index untuk sample bookIndex {bookindex}: {e}"

    sim_scores = list(enumerate(cosine_sim_cb_sample[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:N+1]
    book_indices = [i[0] for i in sim_scores]

    # Kembalikan N buku paling mirip dari SAMPEL
    recommended_books = books_cb_sample.iloc[book_indices][['bookIndex', 'Book Name', 'Author']]
    recommended_books['similarity_score'] = [s[1] for s in sim_scores]
    return recommended_books

# Metrik evaluasi
from sklearn.metrics import ndcg_score
import numpy as np

def precision_at_k(y_true, y_pred, k):
    precisions = []
    for true_items, pred_items in zip(y_true, y_pred):
        pred_k = pred_items[:k]
        hit = len(set(pred_k) & set(true_items))
        precisions.append(hit / k)
    return np.mean(precisions)

def recall_at_k(y_true, y_pred, k):
    recalls = []
    for true_items, pred_items in zip(y_true, y_pred):
        pred_k = pred_items[:k]
        if len(true_items) == 0:
            recalls.append(0)
        else:
            hit = len(set(pred_k) & set(true_items))
            recalls.append(hit / len(true_items))
    return np.mean(recalls)

def ndcg_at_k(y_true, y_pred, k):
    ndcgs = []
    for true_items, pred_items in zip(y_true, y_pred):
        pred_k = pred_items[:k]
        relevance = [1 if item in true_items else 0 for item in pred_k]
        ndcgs.append(ndcg_score([relevance], [relevance]))
    return np.mean(ndcgs)

# Buat ground truth sederhana berdasarkan pengarang yang sama
ground_truth = {}
for idx, row in books_cb_sample.iterrows():
    bookindex = row['bookIndex']
    author = row['Author']
    relevant_books = books_cb_sample[books_cb_sample['Author'] == author]['bookIndex'].tolist()
    relevant_books = [b for b in relevant_books if b != bookindex]  # Exclude diri sendiri
    ground_truth[bookindex] = relevant_books

K = 5
y_true = []
y_pred = []

for bookindex in books_cb_sample['bookIndex']:
    gt = ground_truth.get(bookindex, [])
    recs_df = get_content_based_recommendations_sample(bookindex, N=K)

    if isinstance(recs_df, str):
        continue  # Skip if error

    preds = recs_df['bookIndex'].tolist()
    y_true.append(gt)
    y_pred.append(preds)

# Evaluasi metrik
print(f"\nEvaluasi untuk Content-Based Filtering (K={K}):")
print("Precision@K:", precision_at_k(y_true, y_pred, K))
print("Recall@K:", recall_at_k(y_true, y_pred, K))
print("NDCG@K:", ndcg_at_k(y_true, y_pred, K))

# Contoh penggunaan Content-Based Filtering pada SAMPEL
if not books_cb_sample.empty:
    # Cari bookIndex contoh yang ADA di dalam sampel
    try:
        sample_bookindex_cb_in_sample = books_cb_sample['bookIndex'].iloc[0]
        sample_title_in_sample = books_cb_sample.loc[books_cb_sample['bookIndex'] == sample_bookindex_cb_in_sample, 'Book Name'].values[0]
        print(f"\nRecommendasi untuk buku (dari sample) dengan bookIndex: {sample_bookindex_cb_in_sample} ('{sample_title_in_sample}')")
        recommendations_cb_s = get_content_based_recommendations_sample(sample_bookindex_cb_in_sample, N=5)
        print(recommendations_cb_s)
    except IndexError:
        print("\nDataframe sample kosong, tidak dapat sample bookIndex.")
else:
    print("books_cb_sample dataframe kosong. Tidak dapat menampilkan recommendasi.")

"""- Output ini menunjukkan proses dan hasil dari sistem rekomendasi berbasis konten (content-based recommendation system) yang diterapkan pada dataset buku, contohnya buku-buku yang direkomendasikan dan mirip dengan buku berjudul "'The Invisible Life of Addie LaRue'". Sistem ini menggunakan data buku, menghitung kesamaan antar buku menggunakan representasi TF-IDF dan cosine similarity, kemudian menghasilkan daftar buku rekomendasi bersama dengan skor kesamaan. Hasilnya menunjukkan beberapa buku yang direkomendasikan beserta detailnya, dengan skor kesamaan yang bervariasi, mencerminkan seberapa mirip konten buku-buku.

## Modeling Collaborative Filtering
"""

# Collaborative Filtering
# Menggunakan filtered_ratings_cf yang sudah dipersiapkan
if filtered_ratings_cf.empty:
    print("Lewati Collaborative Filtering karena kolom filtered_ratings_cf kosong.")
else:
    # Persiapan data untuk Surprise
    reader = Reader(rating_scale=(1, 5)) # Rating eksplisit dari 1 hingga 5
    data_cf = Dataset.load_from_df(filtered_ratings_cf[['userId', 'bookIndex', 'score']], reader)

    # Split data menjadi train dan test set
    trainset_cf, testset_cf = surprise_train_test_split(data_cf, test_size=0.2, random_state=42)

    # Menggunakan SVD
    algo_svd = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.02, random_state=42) # Parameter bisa di-tune
    print("\nMelatih model SVD")
    algo_svd.fit(trainset_cf)
    print("SVD model selesai dilatih.")

    # Membuat prediksi pada test set
    predictions_svd = algo_svd.test(testset_cf)

    # Evaluasi model (RMSE dan MAE)
    rmse_svd = accuracy.rmse(predictions_svd)
    mae_svd = accuracy.mae(predictions_svd)
    print(f"SVD - RMSE: {rmse_svd}")
    print(f"SVD - MAE: {mae_svd}")

    # Fungsi untuk mendapatkan top-N rekomendasi untuk pengguna
    def get_collaborative_filtering_recommendations(user_id, N=5):
        # Dapatkan daftar semua bookIndex yang belum dirating oleh pengguna
        rated_bookindex = filtered_ratings_cf[filtered_ratings_cf['userId'] == user_id]['bookIndex'].unique()
        all_bookindex = filtered_ratings_cf['bookIndex'].unique()
        unrated_bookindex = [isbn for isbn in all_bookindex if isbn not in rated_bookindex]

        if not unrated_bookindex:
            return "User has rated all available books or no unrated books found for this user in the filtered set."

        # Prediksi rating untuk buku yang belum dirating
        test_set_for_user = [[user_id, isbn, 0] for isbn in unrated_bookindex] # 0 adalah placeholder
        predictions = algo_svd.test(test_set_for_user)

        predictions.sort(key=lambda x: x.est, reverse=True) # Urutkan berdasarkan estimasi rating

        top_n_predictions = predictions[:N]

        # Dapatkan detail buku untuk rekomendasi
        recommended_book_bookindex = [pred.iid for pred in top_n_predictions]
        recommended_book_details = books_df[books_df['bookIndex'].isin(recommended_book_bookindex)][['bookIndex', 'Book Name', 'Author']]

        # Tambahkan estimasi rating
        # Perlu mencocokkan kembali karena urutan bisa berubah jika ada bookIndex duplikat atau tidak ditemukan
        est_ratings_map = {pred.iid: pred.est for pred in top_n_predictions}
        recommended_book_details['estimated_rating'] = recommended_book_details['bookIndex'].map(est_ratings_map)

        # Urutkan berdasarkan estimasi rating lagi setelah merge
        recommended_book_details = recommended_book_details.sort_values(by='estimated_rating', ascending=False).reset_index(drop=True)

        return recommended_book_details

    # Contoh penggunaan Collaborative Filtering
    if not filtered_ratings_cf.empty:
        # Ambil User-ID contoh dari dataset yang difilter
        sample_user_id_cf = filtered_ratings_cf['userId'].unique()[0]
        print(f"\nRekomendasi untuk userId: {sample_user_id_cf} menggunakan SVD")
        recommendations_cf = get_collaborative_filtering_recommendations(sample_user_id_cf, N=3)
        print(recommendations_cf)
    else:
        print("filtered_ratings_cf kosong. Tidak dapat memberikan rekomendasi CF.")

"""- Hasil dari penerapan model Singular Value Decomposition (SVD) untuk sistem rekomendasi, kemungkinan besar menggunakan pendekatan collaborative filtering. Setelah model SVD dilatih, kinerjanya dievaluasi menggunakan metrik RMSE sebesar 1.4591 dan MAE sebesar 1.2594, yang mengindikasikan tingkat kesalahan prediksi rating.
- Sistem ini memberikan rekomendasi buku yang dipersonalisasi untuk User dengan ID 65674, menyajikan daftar buku beserta perkiraan rating (estimated_rating) yang menunjukkan seberapa besar kemungkinan user tersebut akan menyukai buku-buku yang direkomendasikan berdasarkan pola rating dari user lain.

## Evaluation Content-Based Filtering
"""

# Evaluasi Content-Based Filtering

print("\nEvaluasi Content-Based Filtering")
# Berdasarka visual atau kualitatif, jadi perlu lihat hasilnya dan nilai sendiri.

if not books_cb_sample.empty:
    # Pilih satu buku acak dari sampel untuk diuji
    try:
        random_book_in_sample = books_cb_sample.sample(1, random_state=42).iloc[0]
        bookindex_to_test_simple = random_book_in_sample['bookIndex']
        title_to_test_simple = random_book_in_sample['Book Name']

        print(f"\nMeminta rekomendasi untuk buku (dari sampel):")
        print(f"Book Index: {bookindex_to_test_simple}")
        print(f"Judul: '{title_to_test_simple}'")

        # Dapatkan rekomendasi menggunakan fungsi yang sudah ada
        recommendations_simple = get_content_based_recommendations_sample(bookindex_to_test_simple, N=5)

        # Tampilkan hasil rekomendasi
        if isinstance(recommendations_simple, pd.DataFrame):
            print("\nRekomendasi Teratas:")
            print(recommendations_simple)
        else:
            # Menangani kasus jika bookIndex tidak ditemukan di sampel
            print(recommendations_simple)

    except Exception as e:
        print(f"Terjadi error saat mencoba mendapatkan rekomendasi untuk sampel acak: {e}")

else:
    print("Dataframe sample (books_cb_sample) kosong, tidak bisa melakukan evaluasi sederhana.")

"""- Menyajikan evaluasi dari sistem content-based filtering yang sederhana, di mana sistem memberikan rekomendasi buku berdasarkan kesamaan konten dengan buku input "Glassheart".
- Hasilnya menampilkan daftar buku yang direkomendasikan beserta skor kesamaan mereka.
- Beberapa judul yang direkomendasikan seperti "Majesty (American Royals, #2)" dan "The Invisible Life of Addie LaRue" terlihat terkait skor kesamaan yang relatif rendah (di bawah 0.2) untuk sebagian besar rekomendasi menunjukkan bahwa metode analisis konten atau perhitungan kesamaan yang digunakan mungkin perlu ditingkatkan untuk menghasilkan rekomendasi yang lebih relevan atau serupa secara kuat.
"""

import numpy as np
from sklearn.metrics import ndcg_score

def precision_at_k(y_true, y_pred, k):
    precision_scores = []
    for true, pred in zip(y_true, y_pred):
        pred_k = pred[:k]
        true_set = set(true)
        hit = sum(1 for item in pred_k if item in true_set)
        precision_scores.append(hit / k)
    return np.mean(precision_scores)

def recall_at_k(y_true, y_pred, k):
    recall_scores = []
    for true, pred in zip(y_true, y_pred):
        pred_k = pred[:k]
        true_set = set(true)
        hit = sum(1 for item in pred_k if item in true_set)
        recall_scores.append(hit / len(true_set) if true_set else 0)
    return np.mean(recall_scores)

def ndcg_at_k(y_true, y_pred, k):
    ndcg_scores = []
    for true, pred in zip(y_true, y_pred):
        pred_k = pred[:k]
        true_binary = [1 if item in true else 0 for item in pred_k]
        ndcg_scores.append(ndcg_score([true_binary], [true_binary]))
    return np.mean(ndcg_scores)

# Ground truth dan prediksi dalam bentuk list of lists
y_true = [['book_1', 'book_2'], ['book_3'], ['book_4', 'book_5']]
y_pred = [['book_2', 'book_3', 'book_1'], ['book_3', 'book_6'], ['book_6', 'book_4']]

k = 2
print("Precision@K:", precision_at_k(y_true, y_pred, k))
print("Recall@K:", recall_at_k(y_true, y_pred, k))
print("NDCG@K:", ndcg_at_k(y_true, y_pred, k))

"""## Evaluation Collaborative Filtering"""

# Hasil evaluasi SVD sudah dicetak sebelumnya saat training
if 'rmse_svd' in globals() and 'mae_svd' in globals():
    print("\nMetriks Evaluasi untuk Collaborative Filtering (SVD)")
    print(f"SVD Model - RMSE: {rmse_svd:.4f}")
    print(f"SVD Model - MAE: {mae_svd:.4f}")
    print("\nInterpretasi:")
    print(f"RMSE sebesar {rmse_svd:.4f} menunjukkan bahwa rata-rata, prediksi rating model SVD kita menyimpang sekitar {rmse_svd:.4f} poin rating dari rating sebenarnya, dengan kesalahan yang lebih besar diberi bobot lebih.")
    print(f"MAE sebesar {mae_svd:.4f} menunjukkan bahwa rata-rata, prediksi rating model SVD kita menyimpang sekitar {mae_svd:.4f} poin rating dari rating sebenarnya.")
    print("Nilai ini perlu dipertimbangkan dalam konteks skala rating (1-5). Semakin rendah, semakin baik performa model dalam memprediksi rating.")
else:
    print("\nMelewati evaluasi CF dengan SVD model hasilnya tidak ada (seperti jika kolom filtered_ratings_cf kosong).")

"""- Metrik evaluasi untuk model Collaborative Filtering menggunakan metode SVD, dengan nilai RMSE sebesar 1.4591 dan MAE sebesar 1.2594.
- Nilai-nilai ini mengindikasikan performa model dalam memprediksi rating pengguna; secara rata-rata, prediksi rating model SVD menyimpang sekitar 1.4591 poin dari rating sebenarnya (dengan penalti lebih besar untuk kesalahan besar) dan memiliki rata-rata selisih absolut 1.2594 poin dari rating sebenarnya.
- Dalam konteks skala rating 1-5, semakin rendah nilai RMSE dan MAE, semakin baik kemampuan model dalam memprediksi rating, sehingga nilai-nilai ini memberikan gambaran kuantitatif tentang akurasi rekomendasi yang dihasilkan oleh model SVD ini.
"""

